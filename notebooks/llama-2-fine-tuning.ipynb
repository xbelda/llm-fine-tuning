{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfecba83-af46-47ad-9eaa-2c20990e4b4e",
   "metadata": {},
   "source": [
    "- https://huggingface.co/docs/trl/main/en/sft_trainer\n",
    "- https://deci.ai/blog/fine-tune-llama-2-with-lora-for-question-answering/\n",
    "- https://www.kaggle.com/code/debarshichanda/qlora-falcon-7b-training\n",
    "- https://archive.md/oNOCJ#selection-1495.0-1495.17\n",
    "\n",
    "# TODO:\n",
    "-  try: `neftune_noise_alpha=5`\n",
    "-  Install `flash-attn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d98e805-b133-4863-894e-83ea9f396557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xavi/projects/llm-fine-tuning\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import SFTTrainer, PPOTrainer, DataCollatorForCompletionOnlyLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f78f653a3158bb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59f27c-f3cd-4e92-bb9e-f0a0edf2469c",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb6ef40-33b2-49c5-905e-cbfa9094909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432e410-3288-49cd-82f5-09228ac382dc",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f184427a-2cdc-4c81-b749-b55d71aa3e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['original dialog id', 'new dialog id', 'dialog index', 'original dialog info', 'log', 'prompt'],\n",
       "        num_rows: 879\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['original dialog id', 'new dialog id', 'dialog index', 'original dialog info', 'log', 'prompt'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['original dialog id', 'new dialog id', 'dialog index', 'original dialog info', 'log', 'prompt'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Salesforce/dialogstudio\", \"TweetSumm\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57eebf9a-bc9c-4988-8986-722eed99f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "Below is a conversation between a human and an AI agent. Write a summary of the conversation.\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_training_prompt(\n",
    "    conversation: str, summary: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT\n",
    ") -> str:\n",
    "    conversation = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": DEFAULT_SYSTEM_PROMPT,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": conversation.strip()\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": summary.strip()\n",
    "    },\n",
    "]\n",
    "    \n",
    "    return tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b3b7b0-eb1b-4693-a1f3-d060c0b22a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@[^\\s]+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\^[^ ]+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def create_conversation_text(data_point):\n",
    "    text = \"\"\n",
    "    for item in data_point[\"log\"]:\n",
    "        user = clean_text(item[\"user utterance\"])\n",
    "        text += f\"user: {user.strip()}\\n\"\n",
    "\n",
    "        agent = clean_text(item[\"system response\"])\n",
    "        text += f\"agent: {agent.strip()}\\n\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3206f6f2-7cee-4f14-bb6b-af622a1d93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(data_point) -> dict[str, str]:\n",
    "    summaries = json.loads(data_point[\"original dialog info\"])[\"summaries\"][\"abstractive_summaries\"]\n",
    "    summary = summaries[0]\n",
    "    summary = \" \".join(summary)\n",
    "\n",
    "    conversation_text = create_conversation_text(data_point)\n",
    "    return {\n",
    "        \"conversation\": conversation_text,\n",
    "        \"summary\": summary,\n",
    "        \"text\": generate_training_prompt(conversation_text, summary),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f28eb9e-d611-48d6-9276-89adba57a04a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation': 'user: So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? please read the above.\\nagent: Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\\nuser: My iPhone is on 11.1.2, and my watch is on 4.1.\\nagent: Thank you. Have you tried restarting both devices since this started happening?\\nuser: I’ve restarted both, also un-paired then re-paired the watch.\\nagent: Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?\\nuser: Yes, everything seems fine, it’s just Health and activity.\\nagent: Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app?\\n',\n",
       " 'summary': 'Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.',\n",
       " 'text': '<s>[INST] <<SYS>>\\nBelow is a conversation between a human and an AI agent. Write a summary of the conversation.\\n<</SYS>>\\n\\nuser: So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? please read the above.\\nagent: Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\\nuser: My iPhone is on 11.1.2, and my watch is on 4.1.\\nagent: Thank you. Have you tried restarting both devices since this started happening?\\nuser: I’ve restarted both, also un-paired then re-paired the watch.\\nagent: Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?\\nuser: Yes, everything seems fine, it’s just Health and activity.\\nagent: Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app? [/INST] Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it. </s>'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = generate_text(dataset[\"train\"][0])\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe43cf71-3589-4343-b637-eec8149ccb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(data: Dataset):\n",
    "    return (\n",
    "        data.shuffle(seed=42)\n",
    "        .map(generate_text)\n",
    "        .remove_columns(\n",
    "            [\n",
    "                \"original dialog id\",\n",
    "                \"new dialog id\",\n",
    "                \"dialog index\",\n",
    "                \"original dialog info\",\n",
    "                \"log\",\n",
    "                \"prompt\",\n",
    "            ]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edafd86c-758b-4c04-90c1-46a128c7319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = process_dataset(dataset[\"train\"])\n",
    "dataset[\"validation\"] = process_dataset(dataset[\"validation\"])\n",
    "dataset[\"test\"] = process_dataset(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f48ba5c-6d49-45b2-8164-8dda468f8d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversation', 'summary', 'text'],\n",
       "        num_rows: 879\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['conversation', 'summary', 'text'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['conversation', 'summary', 'text'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa485cd-b59b-47b4-98f7-50782416359c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5edfe67c-8757-46e3-b521-aa5c9798c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_tokenizer():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        use_safetensors=True,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c566e280-b123-4e49-86da-7890a1eee89c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b504c798c0842d98c38133f21fb80fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model_and_tokenizer()\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ca7c772-d70f-4789-9e63-efa5d35c3cd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_method': <QuantizationMethod.BITS_AND_BYTES: 'bitsandbytes'>,\n",
       " 'load_in_8bit': False,\n",
       " 'load_in_4bit': True,\n",
       " 'llm_int8_threshold': 6.0,\n",
       " 'llm_int8_skip_modules': None,\n",
       " 'llm_int8_enable_fp32_cpu_offload': False,\n",
       " 'llm_int8_has_fp16_weight': False,\n",
       " 'bnb_4bit_quant_type': 'nf4',\n",
       " 'bnb_4bit_use_double_quant': False,\n",
       " 'bnb_4bit_compute_dtype': 'float16'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.quantization_config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8531d04-bead-45ba-ad43-a4f3df3715ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_alpha = 32\n",
    "lora_dropout = 0.05\n",
    "lora_r = 16\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f184d2a-a501-4934-bf0d-b7dc40b6e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add special separation tokens\n",
    "response_template_with_context = \"[/INST]\"  # We added context here: \"\\n\". This is enough for this tokenizer\n",
    "response_template_ids = tokenizer.encode(response_template_with_context, add_special_tokens=False) # [2:]  # Now we have it like in the dataset texts: `[2277, 29937, 4007, 22137, 29901]`\n",
    "\n",
    "data_collator = DataCollatorForCompletionOnlyLM(response_template_ids, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55196aae-536e-490f-be6f-bb974675ce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c11f6a05-3208-41fa-8d96-fac411a082bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"epoch\",\n",
    "    group_by_length=True,\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=42,\n",
    "    output_dir=OUTPUT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29060a92-8a32-4a9e-8eeb-097b99000818",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_train,  #dataset[\"train\"],\n",
    "    eval_dataset=dataset_validation,  #dataset[\"validation\"],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    data_collator=data_collator,\n",
    "    # neftune_noise_alpha=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d7fe13a-e37d-40a1-b72d-01ef7bf07e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 1:13:50, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.374200</td>\n",
       "      <td>2.113874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.512200</td>\n",
       "      <td>2.067321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.321000</td>\n",
       "      <td>2.049923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.395900</td>\n",
       "      <td>2.036112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.362700</td>\n",
       "      <td>2.033348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=2.1598494879603387, metrics={'train_runtime': 4434.4161, 'train_samples_per_second': 1.804, 'train_steps_per_second': 0.451, 'total_flos': 1.0999808606099866e+17, 'train_loss': 2.1598494879603387, 'epoch': 2.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63204bcf-a801-496e-85c4-4322efc78faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "trainer.model.save_pretrained(\"models/my-fine-tuned-model-2\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9b917ab-12b9-4098-bab3-e5dc48f985da",
   "metadata": {},
   "source": [
    "# Load LoRA weights\n",
    "model = AutoModelForCausalLM.from_pretrained(\"llama-2-7b-fine-tuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
