{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfecba83-af46-47ad-9eaa-2c20990e4b4e",
   "metadata": {},
   "source": [
    "- https://huggingface.co/docs/trl/main/en/sft_trainer\n",
    "- https://deci.ai/blog/fine-tune-llama-2-with-lora-for-question-answering/\n",
    "\n",
    "# TODO:\n",
    "-  try: `neftune_noise_alpha=5`\n",
    "-  Install `flash-attn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98e805-b133-4863-894e-83ea9f396557",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import SFTTrainer, PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f78f653a3158bb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "# MODEL_NAME = \"NousResearch/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59f27c-f3cd-4e92-bb9e-f0a0edf2469c",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6ef40-33b2-49c5-905e-cbfa9094909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432e410-3288-49cd-82f5-09228ac382dc",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184427a-2cdc-4c81-b749-b55d71aa3e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Salesforce/dialogstudio\", \"TweetSumm\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eebf9a-bc9c-4988-8986-722eed99f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "Below is a conversation between a human and an AI agent. Write a summary of the conversation.\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_training_prompt(\n",
    "    conversation: str, summary: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT\n",
    ") -> str:\n",
    "    conversation = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": DEFAULT_SYSTEM_PROMPT,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": conversation.strip()\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": summary.strip()\n",
    "    },\n",
    "]\n",
    "    \n",
    "    return tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3b7b0-eb1b-4693-a1f3-d060c0b22a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@[^\\s]+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\^[^ ]+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def create_conversation_text(data_point):\n",
    "    text = \"\"\n",
    "    for item in data_point[\"log\"]:\n",
    "        user = clean_text(item[\"user utterance\"])\n",
    "        text += f\"user: {user.strip()}\\n\"\n",
    "\n",
    "        agent = clean_text(item[\"system response\"])\n",
    "        text += f\"agent: {agent.strip()}\\n\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3206f6f2-7cee-4f14-bb6b-af622a1d93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(data_point) -> dict[str, str]:\n",
    "    summaries = json.loads(data_point[\"original dialog info\"])[\"summaries\"][\"abstractive_summaries\"]\n",
    "    summary = summaries[0]\n",
    "    summary = \" \".join(summary)\n",
    "\n",
    "    conversation_text = create_conversation_text(data_point)\n",
    "    return {\n",
    "        \"conversation\": conversation_text,\n",
    "        \"summary\": summary,\n",
    "        \"text\": generate_training_prompt(conversation_text, summary),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28eb9e-d611-48d6-9276-89adba57a04a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example = generate_text(dataset[\"train\"][0])\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43cf71-3589-4343-b637-eec8149ccb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(data: Dataset):\n",
    "    return (\n",
    "        data.shuffle(seed=42)\n",
    "        .map(generate_text)\n",
    "        .remove_columns(\n",
    "            [\n",
    "                \"original dialog id\",\n",
    "                \"new dialog id\",\n",
    "                \"dialog index\",\n",
    "                \"original dialog info\",\n",
    "                \"log\",\n",
    "                \"prompt\",\n",
    "            ]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edafd86c-758b-4c04-90c1-46a128c7319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = process_dataset(dataset[\"train\"])\n",
    "dataset[\"validation\"] = process_dataset(dataset[\"validation\"])\n",
    "dataset[\"test\"] = process_dataset(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f48ba5c-6d49-45b2-8164-8dda468f8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa485cd-b59b-47b4-98f7-50782416359c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edfe67c-8757-46e3-b521-aa5c9798c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_tokenizer():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        use_safetensors=True,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c566e280-b123-4e49-86da-7890a1eee89c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_model_and_tokenizer()\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7c772-d70f-4789-9e63-efa5d35c3cd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.config.quantization_config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8531d04-bead-45ba-ad43-a4f3df3715ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_alpha = 64\n",
    "lora_dropout = 0.05\n",
    "lora_r = 32\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f429a60-5980-4325-bed7-9b7c13b3625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f6a05-3208-41fa-8d96-fac411a082bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"epoch\",\n",
    "    group_by_length=True,\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=42,\n",
    "    output_dir=OUTPUT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29060a92-8a32-4a9e-8eeb-097b99000818",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    # neftune_noise_alpha=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fdd920-cfdc-4c69-b0cc-a0469140bf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7fe13a-e37d-40a1-b72d-01ef7bf07e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6840296f-9873-4b7e-a376-c7959ac5817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "trainer.model.save_pretrained(\"models/llama-2-7b-fine-tuned\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9b917ab-12b9-4098-bab3-e5dc48f985da",
   "metadata": {},
   "source": [
    "# Load LoRA weights\n",
    "model = AutoModelForCausalLM.from_pretrained(\"llama-2-7b-fine-tuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
